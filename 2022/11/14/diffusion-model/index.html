<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Diffusion Model介绍 | Yuddi的个人博客</title><meta name="author" content="Yuddi"><meta name="copyright" content="Yuddi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="主要介绍了扩散模型的一些概要以及与NCSN，SDE模型的关系">
<meta property="og:type" content="article">
<meta property="og:title" content="Diffusion Model介绍">
<meta property="og:url" content="http://example.com/2022/11/14/diffusion-model/index.html">
<meta property="og:site_name" content="Yuddi的个人博客">
<meta property="og:description" content="主要介绍了扩散模型的一些概要以及与NCSN，SDE模型的关系">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/diffusion_model/DDPM.png">
<meta property="article:published_time" content="2022-11-14T03:31:40.000Z">
<meta property="article:modified_time" content="2022-11-15T02:28:18.444Z">
<meta property="article:author" content="Yuddi">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/diffusion_model/DDPM.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/11/14/diffusion-model/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Diffusion Model介绍',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-15 10:28:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/diffusion_model/DDPM.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yuddi的个人博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Diffusion Model介绍</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-11-14T03:31:40.000Z" title="Created 2022-11-14 11:31:40">2022-11-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-11-15T02:28:18.444Z" title="Updated 2022-11-15 10:28:18">2022-11-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Algorithms/">Algorithms</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Diffusion Model介绍"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>&emsp;&emsp;目前在机器学习中主要有两大类模型，分别为生成式模型与判别式模型。这两类模型在性质与任务上都有着比较大的区别。如下图所示。判别式模型如图左所示，其主要学习到的是两张图片之间的区别，不需要过多了解到图片本身的特征，他不需要知道猫和狗具体特征，只需要知道两者不同的地方即可。因此也称之为<strong>判别式模型</strong>。而生成式模型如图右所示，其需要学习到猫和狗的各自的具体特征，并对其本身分布进行学习，然后得出其为猫或狗的结论，由于学习到了其本身的分布，便可以根据其分布进行采样生成其他类似的图片，因此其被称之为<strong>生成式模型</strong>。<br><img src="/img/diffusion_model/generative_model.png" alt=""><br>具体公式表示如下：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
P & (Y|X=x)\\

&P(X,Y)
\end{aligned}
\end{equation}</script><p>生成模型主要分为两个步骤，首先是建模，需要对目标数据的分布进行学习。然后则是采样，通过对分布$P(X)$进行采样生成数据。<br><img src="/img/diffusion_model/generative_procedures.png" alt=""></p>
<p>&emsp;&emsp;下图是生成模型的一个实例，通过对猫咪的图片进行学习，得到其目标分布之后进行采样得到新的生成的猫咪的图片。<br><img src="/img/diffusion_model/generative_cat.png" alt=""></p>
<p>&emsp;&emsp;目前根据是否显式的表现数据分布$P(X)$,将生成模型主要分为两类。大家耳熟能详的变分自编码器VAE便属于其中一类根据最大似然直接学习数据分布的表示的模型，称之为<strong>likelihood-based models</strong>；而生成对抗网络GAN则是对数据进行隐式的学习，称之为<strong>implicit generative models</strong>。<br><img src="/img/diffusion_model/category.png" alt=""></p>
<h2 id="变分自编码器-Variable-Autoencoder"><a href="#变分自编码器-Variable-Autoencoder" class="headerlink" title="变分自编码器 Variable Autoencoder"></a>变分自编码器 Variable Autoencoder</h2><p>&emsp;&emsp;变分自编码器是对一种采用变分后验来近似真实后验的生成式模型。由于高维流型假说：我们所能观察到的数据实际上是由一个低维流形映射到高维空间上的。由于数据内部特征的限制，一些高维中的数据会产生维度上的冗余，实际上只需要比较低的维度就能唯一地表示。因此在VAE中，模型先通过编码器将高维数据映射到低维隐变量$Z$中，然后再通过解码器$P(X|Z)$得到$X$的分布。因此我们可以得到$P(X)$如下所示：</p>
<script type="math/tex; mode=display">
P(X) =  \int P(X|Z)P(Z)dz</script><p>理论上我们只需要解码器就可得到生成数据，但是对上式进行积分计算十分困难，因此考虑先计算后验概率$P(Z|X)$，然后再通过如下公式：</p>
<script type="math/tex; mode=display">
\log p_\theta(x) = \log \frac{p_\theta(x|z)p(z)}{p_\theta(z|x)}</script><p>得到最终的$P(X)$。但是后验概率也比较难计算，因此进一步提出了变分后验$q_\theta(z|x)$来近似真实的后验分布$p_\theta(z|x)$。同时为了简单起见，模型限制隐变量$P(Z)\sim N(0,1)$。<br><img src="/img/diffusion_model/VAE-graphical-model.png" alt=""></p>
<p>基于最大似然的方法对其求解：</p>
<script type="math/tex; mode=display">
\begin{equation*}
\begin{aligned}
\log p_\theta(x) &= \mathbb{E}_{q_\phi (z|x)}[\log \frac{p_\theta(x|z)p(z)}{q_\phi (z|x)}] + D_{KL}(q_\theta(z|x)||p_\theta(z|x)) \\

&\geq \mathbb{E}_{q_\phi (z|x)}[\log \frac{p_\theta(x|z)p(z)}{q_\phi (z|x)}] \\
&=\mathbb{E}_{q_\phi (z|x)}[\log p_\theta(x|z) + \log p(z)-\log q_\phi (z|x)]
\end{aligned}
\end{equation*}</script><p>以上式子中$\log p_\theta(x|z)$表示解码器，也就是生成器的数据准确度。而$\log p(z)-\log q_\phi (z|x)$则表示隐变量与变分后验的KL散度。因此VAE主要由两部分loss构成，分别是解码器输出的$x’$与$x$的L2loss以及编码器输出的分布与隐变量分布(高斯分布)的KL散度。<br><img src="/img/diffusion_model/VAE.png" alt=""></p>
<h1 id="Denoising-diffusion-probabilistic-models"><a href="#Denoising-diffusion-probabilistic-models" class="headerlink" title="Denoising diffusion probabilistic models"></a>Denoising diffusion probabilistic models</h1><p>&emsp;&emsp;扩散模型最初是由Jascha Sohl-Dickstein等人在2015年根据非平衡统计物理学 (Jarzynski, 1997) 和顺序蒙特卡洛 (Neal, 2001)设计的一种生成式模型。该模型能够兼顾灵活性以及易计算性，分为两个过程，分别为前向过程以及逆向过程。首先通过前向加噪过程将其目标分布转换为另一种平稳分布，然后通过逆向过程恢复目标分步。此模型的好处在于其前向过程是固定的，且可拟合恢复出任意分布。<br><img src="/img/diffusion_model/diffusion_model.png" alt=""></p>
<p>&emsp;&emsp;而在2020年，由Jonathan Ho等人对其进行了改进，提出了Denoising diffusion probabilistic model. 该模型相比于原本的扩散模型对其前向和后向过程都做了改进。</p>
<ol>
<li>前向过程中，其固定了一些扩散系数，不需要通过学习来得到</li>
<li>反向过程中，其对一些训练策略进行了改进<br><img src="/img/diffusion_model/denoising_diffusion_model.png" alt=""></li>
</ol>
<h2 id="Forward-diffusion"><a href="#Forward-diffusion" class="headerlink" title="Forward diffusion"></a>Forward diffusion</h2><p>&emsp;&emsp;denosing diffusion probabilistic model的前向扩散过程为高斯加噪过程，其定义如下：</p>
<script type="math/tex; mode=display">
q(x_t|x_{t-1}) = N(x_t;\sqrt{1-\beta_t} x_{t-1},\beta_t I), 0<\beta_t < 1</script><p>因此根据重参数化技巧，我们进而可以得到如下公式：</p>
<script type="math/tex; mode=display">
x_t = \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t}\epsilon_{t-1}, \epsilon_{t-1} \sim N(0,1)</script><p>令$ \alpha_t = 1 - \beta_t, \bar{\alpha}_t = \prod_{i=1}^t \alpha_i$后对上述公式递归:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{x}_t 
&= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}_{t-1} & \text{ ;where } \boldsymbol{\epsilon}_{t-1}, \boldsymbol{\epsilon}_{t-2}, \dots \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\boldsymbol{\epsilon}}_{t-2} & \text{ ;where } \bar{\boldsymbol{\epsilon}}_{t-2} \text{ merges two Gaussians (*).} \\
&= \dots \\
&= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon} 
\end{aligned}</script><p>我们最终可以得到：</p>
<script type="math/tex; mode=display">
q(\mathbf{x}_t \vert \mathbf{x}_0) = N(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})</script><p>通过上式我们可以得出：对于任一时间$t$，我们都可以通过对$x_0$采样得到。</p>
<h2 id="Reverse-process"><a href="#Reverse-process" class="headerlink" title="Reverse process"></a>Reverse process</h2><p>&emsp;&emsp;当$\beta_t$足够小时，其反向扩散过程$q(x_{t-1}|x_t)$也是一个高斯过程。</p>
<script type="math/tex; mode=display">
q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t \mathbf{I})</script><p>而其均值和方差具体表达式如下：</p>
<script type="math/tex; mode=display">
\begin{equation*}
\begin{aligned}

\tilde{\boldsymbol{\mu}}_t(x_t,x_0)
&= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0\\

&= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t) \\
&= \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)\\


\tilde{\beta}_t  &
= \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t

\end{aligned}
\end{equation*}</script><p><img src="/img/diffusion_model/diffusion_model_reverse.png" alt=""><br>因此采用学习$p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) = N(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))$来近似$q(x_t|x_{t-1})$。</p>
<h2 id="Comparing-Denoising-diffusion-probabilistic-models-and-VAE"><a href="#Comparing-Denoising-diffusion-probabilistic-models-and-VAE" class="headerlink" title="Comparing Denoising diffusion probabilistic models and VAE"></a>Comparing Denoising diffusion probabilistic models and VAE</h2><p>对比上图的扩散模型以及VAE模型架构，其实可以发现其有很多相似之处。扩散模型可以看做一个马尔科夫链的VAE，但是有以下三点限制：</p>
<ol>
<li>其隐变量维度与数据维度相等</li>
<li>隐变量编码器的架构是提前定义好的</li>
<li>隐变量编码器的高斯参数是随着时间变化的</li>
</ol>
<p>其实，VAE的设计思想是定义了生成器，然后再定义变分后验来适应生成器做训练，需要同时训练编码器和解码器；而扩散模型则是固定了前向过程，只需要训练后向过程即可。那么我们便可以像VAE一样基于最大似然去优化表达式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\log p_\theta(\mathbf{x}_0) 
&\geq \mathbb{E}_q \Big[ \log \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)} \Big] \\


&= \mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0} ]
\end{aligned}</script><p>而其中：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_t &= D_\text{KL}(q(\mathbf{x}_t \vert \mathbf{x}_{t+1}, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_t \vert\mathbf{x}_{t+1})) \text{ for }1 \leq t \leq T-1 \\
&= D_\text{KL}(\mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t \mathbf{I})\parallel N(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))) \\
&=\frac{1}{2||\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)||_2^2}||\tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0)-\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)||^2
\end{aligned}</script><p>根据上文得到的$\tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0)$公式可以得到其与$t$时刻的数据以及噪声有关，因此我们可以令：</p>
<script type="math/tex; mode=display">
\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(x_t,t) \Big)</script><p>进而：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_t 
&= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2 \| \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) \|^2_2} \| \tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0) - \boldsymbol{\mu}_\theta(\mathbf{x}_t, t) \|^2 \Big] \\
&= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2  \|\boldsymbol{\Sigma}_\theta \|^2_2} \| \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big) - \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t) \Big) \|^2 \Big] \\
&= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\
&= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2 \Big] 
\end{aligned}</script><p>于是，通过简化以及实验验证，我们可以得到最终的优化公式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_t^\text{simple}
&= \mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[\|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\
&= \mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[\|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2 \Big]
\end{aligned}</script><p>由于方差为一个定值，因此为了简单起见，同时也因为实验验证，在原文中其去掉了权重。至此，denoising diffusion probablistic model推理完成。其具体算法步骤如下所示：<br><img src="/img/diffusion_model/algorithm.png" alt=""></p>
<h1 id="Noise-Conditional-Score-Network"><a href="#Noise-Conditional-Score-Network" class="headerlink" title="Noise Conditional Score Network"></a>Noise Conditional Score Network</h1><p>对于生成式模型，我们期望能够对齐概率密度函数pdf进行拟合以及学习，因此我们用如下公式来表示任意的概率密度函数:</p>
<script type="math/tex; mode=display">

p_\theta(x) = \frac{e^{-f_\theta (x)}}{Z_\theta}</script><p>&emsp;&emsp;其中$e^{-f_\theta (x)}$称之为energy-based model,而$Z_\theta$则是归一化常数，其目的是为了保证$p_\theta(x)$的积分为1。由于归一化常数难以处理与计算，因此其对于生成式模型有多中限制。现有的很多模型为了满足其要求要么限制其模型结构或者近似归一化常数，如VAE。这些都会导致计算耗费较大。<br><img src="/img/diffusion_model/pdf.gif" alt=""></p>
<p>&emsp;&emsp;因此进一步提出了分数函数$\bigtriangledown_x \log p(x)$以及基于分数的模型score-based model$s_\theta(x)$来近似分数函数$s_\theta(x) \approx \bigtriangledown_x \log p(x)$,那分数函数相比于原本的函数有什么优势呢？</p>
<script type="math/tex; mode=display">
\mathbf{s}_\theta (\mathbf{x}) = \nabla_{\mathbf{x}} \log p_\theta (\mathbf{x} ) = -\nabla_{\mathbf{x}} f_\theta (\mathbf{x}) - \underbrace{\nabla_\mathbf{x} \log Z_\theta}_{=0} = -\nabla_\mathbf{x} f_\theta(\mathbf{x})</script><p>相比于原本的pdf，分数函数消除了归一化常数的影响。进而像之前基于最大似然的求解方法一样，可以采用最小化Fisher divergence的方法来训练基于分数的模型。</p>
<script type="math/tex; mode=display">
\mathbb{E}_{p(\mathbf{x})}[\| \nabla_\mathbf{x} \log p(\mathbf{x}) - \mathbf{s}_\theta(\mathbf{x}) \|_2^2]</script><p>但是不知道$\bigtriangledown_x \log p(x)$的groud truth如何进行训练呢？这个时候便有一种方法称之为score-matching，能够在不知道其gt的情况下，训练得到$s_\theta(x)$。而且其不需要像GAN那一样进行对抗训练，只需要最小化目标函数即可，避免了mode collapse的风险。那么在学习到了$s_\theta(x) \approx \bigtriangledown_x \log p(x)$，如何能够采样得到x呢？</p>
<h2 id="Langevin-dynamics"><a href="#Langevin-dynamics" class="headerlink" title="Langevin dynamics"></a>Langevin dynamics</h2><p>郎之万动力学是一种能够依赖于梯度进行迭代过程采样得到目标数据的方法。</p>
<script type="math/tex; mode=display">
\mathbf{x}_{i+1} \gets \mathbf{x}_i + \epsilon \nabla_\mathbf{x} \log p(\mathbf{x}) + \sqrt{2\epsilon}~ \mathbf{z}_i, \quad i=0,1,\cdots, K, \quad \mathbf{z}_i \sim \mathcal{N}(0, I)</script><p>其初始化$x_0$可以服从任意分布，都可以通过郎之万动力学的式子采样得到满足最终$p(x)$分布的数据。而当$\epsilon \to 0, K \to \infty$，其误差可以忽略不计。<br><img src="/img/diffusion_model/langevin_dynamics.gif" alt=""></p>
<p>因此我们最终得到了基于分数的生成模型。<br><img src="/img/diffusion_model/score_based_generative_model.jpg" alt=""><br>但是其还存在着一定的缺陷。</p>
<script type="math/tex; mode=display">
\mathbb{E}_{p(\mathbf{x})}[\| \nabla_\mathbf{x} \log p(\mathbf{x}) - \mathbf{s}_\theta(\mathbf{x}) \|_2^2] = \int {\color{red}{p(\mathbf{x})}}  \| \nabla_\mathbf{x} \log p(\mathbf{x}) - \mathbf{s}_\theta(\mathbf{x}) \|_2^2 \mathrm{d}\mathbf{x}.</script><p>我们可以看到最小化Fisher divergence式子中的权重为$p(x)$，也就是说<strong>x</strong>密度大的地方学习的较好，而密度小的地方学习效果较差，即如下所示：<br><img src="/img/diffusion_model/density.jpg" alt=""><br>而当使用郎之万动力学模型采样时，很有可能其初始化在低密度区域，因此会造成最终采样出现偏差。因此提出了Noise Conditional Score Network。通过对输入数据进行噪声扰动来消除上述学习不完全的缺陷。通过对输入数据添加噪声进行扰动，来使其密度分布的更广泛，如下所示：<br><img src="/img/diffusion_model/noise.jpg" alt=""><br>但是对于噪声的选择便有了问题，当噪声过大时，其的确会覆盖更多的低密度区域，但是也会影响数据的原始分布；当噪声过小时，虽然不会过多地影响原始分布，但是不能很好的覆盖低密度区域。因此Noise Conditional Score Network(NCSN)选择多种强度的噪声进行数据扰动。总共有$L$中强度不同的高斯噪声$\mathcal{N}(0, \sigma_i^2 I), i=1,2,\cdots,L, \sigma_1 &lt; \sigma_2 &lt; \cdots &lt; \sigma_L$，对数据分布$P(x)$进行扰动。</p>
<script type="math/tex; mode=display">
p_{\sigma_i}(\mathbf{x}) = \int p(\mathbf{y}) \mathcal{N}(\mathbf{x}; \mathbf{y}, \sigma_i^2 I) \mathrm{d} \mathbf{y}.</script><p>其都是直接对原始数据分布进行扰动，不会进行叠加。<br><img src="/img/diffusion_model/different_noise.jpg" alt=""><br>实例如下所示：<br><img src="/img/diffusion_model/different_noise_dog.jpg" alt=""><br>之后我们再采用score-based model来学习扰动后的数据$\mathbf{s}_\theta(\mathbf{x}, i) \approx \nabla_\mathbf{x} \log p_{\sigma_i}(\mathbf{x})$。与之前相似，我们同样采用最小化Fisher divergence的方法来进行训练</p>
<script type="math/tex; mode=display">
\begin{equation*} 
\begin{aligned}
&\sum_{i=1}^L \lambda(i) \mathbb{E}_{p_{\sigma_i}(\mathbf{x})}[\| \nabla_\mathbf{x} \log p_{\sigma_i}(\mathbf{x}) - \mathbf{s}_\theta(\mathbf{x}, i) \|_2^2] \\
=  &\sum_{i=1}^L \lambda(i) \mathbb{E}_{p_{\sigma_i}(\mathbf{x})}[\| \mathbf{s}_\theta(\mathbf{x}, i)+ \frac{\epsilon}{\sigma_i} \|_2^2]
\end{aligned}
\end{equation*}</script><p>我们会发现其最终学习的也是噪声，与DDPM是相似的，那么两者有啥联系呢？这个我们会在下一节讲解。那么学习到了新的score-based model之后，如何继续采用郎之万动力学方法采样呢？对于噪声扰动后的数据，采样方法从原本的郎之万动力学方法改进为退火郎之万动力学方法。其思想相对来说比较简单，首先在噪声强度大的数据上进行郎之万动力学采样，然后在其基础上逐渐减小噪声强度继续进行郎之万动力学的方法进行采样。<br><img src="/img/diffusion_model/annealed_langevin_dynamics.gif" alt=""></p>
<h1 id="Stochastic-differential-equations"><a href="#Stochastic-differential-equations" class="headerlink" title="Stochastic differential equations"></a>Stochastic differential equations</h1><p>这节会讲述将DDPM与NCSN进行统一的方法。当噪声扰动的步骤变为无穷大时，其便转换为了一个连续的随机过程。而这种随机过程则是随机微分方程(Stochastic differential equations, SDE)的解。SDE表达式如下所示：</p>
<script type="math/tex; mode=display">
\mathrm{d}\mathbf{x} = \mathbf{f}(\mathbf{x}, t) \mathrm{d}t + g(t) \mathrm{d} \mathbf{w}</script><p>$\mathbf{f}(\mathbf{x}, t)$称之为漂移系数，而$g(t)$称为扩散系数，$\mathrm{d} \mathbf{w}$则是标准布朗运动。SDE为正向加噪过程，则我们可以通过反向SDE方程进行采样。其表达式如下：</p>
<script type="math/tex; mode=display">
\mathrm{d}\mathbf{x} = [\mathbf{f}(\mathbf{x}, t) - g^2(t) \nabla_\mathbf{x} \log p_t(\mathbf{x})]\mathrm{d}t + g(t) \mathrm{d} \mathbf{w}</script><p><img src="/img/diffusion_model/sde_schematic.jpg" alt=""><br>上述提到的DDPM以及NCSN都可以看做是SDE的特例。</p>
<p>对于DDPM来说，其正向加噪过程当$N \rightarrow \infty$，SDE相应的公式为：</p>
<script type="math/tex; mode=display">
dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)}dw</script><p>对于NCSN来说，其正向加噪过程当$N \rightarrow \infty$，SDE相应的公式为：</p>
<script type="math/tex; mode=display">
dx = \sqrt{\frac{d[\sigma^2(t)]}{dt}}dw</script><p>因此，通过对SDE以及reverse SDE进行求解便可完成加噪和采样过程。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://example.com">Yuddi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/11/14/diffusion-model/">http://example.com/2022/11/14/diffusion-model/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a></div><div class="post_share"><div class="social-share" data-image="/img/diffusion_model/DDPM.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/10/31/Icarus-Verilog%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"><img class="next-cover" src="/img/Icarus_Verilog/top_cover.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Icarus_Verilog的安装与使用</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/10/31/%E5%9F%BA%E4%BA%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/" title="基于全连接神经网络的MNIST手写数字识别"><img class="cover" src="/img/MNIST/top_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-31</div><div class="title">基于全连接神经网络的MNIST手写数字识别</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Yuddi</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Yuddicpp"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Yuddicpp" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Study Together</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8-Variable-Autoencoder"><span class="toc-number">1.1.</span> <span class="toc-text">变分自编码器 Variable Autoencoder</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Denoising-diffusion-probabilistic-models"><span class="toc-number">2.</span> <span class="toc-text">Denoising diffusion probabilistic models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Forward-diffusion"><span class="toc-number">2.1.</span> <span class="toc-text">Forward diffusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reverse-process"><span class="toc-number">2.2.</span> <span class="toc-text">Reverse process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Comparing-Denoising-diffusion-probabilistic-models-and-VAE"><span class="toc-number">2.3.</span> <span class="toc-text">Comparing Denoising diffusion probabilistic models and VAE</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Noise-Conditional-Score-Network"><span class="toc-number">3.</span> <span class="toc-text">Noise Conditional Score Network</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Langevin-dynamics"><span class="toc-number">3.1.</span> <span class="toc-text">Langevin dynamics</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Stochastic-differential-equations"><span class="toc-number">4.</span> <span class="toc-text">Stochastic differential equations</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/11/14/diffusion-model/" title="Diffusion Model介绍"><img src="/img/diffusion_model/DDPM.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Diffusion Model介绍"/></a><div class="content"><a class="title" href="/2022/11/14/diffusion-model/" title="Diffusion Model介绍">Diffusion Model介绍</a><time datetime="2022-11-14T03:31:40.000Z" title="Created 2022-11-14 11:31:40">2022-11-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/31/Icarus-Verilog%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/" title="Icarus_Verilog的安装与使用"><img src="/img/Icarus_Verilog/top_cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Icarus_Verilog的安装与使用"/></a><div class="content"><a class="title" href="/2022/10/31/Icarus-Verilog%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/" title="Icarus_Verilog的安装与使用">Icarus_Verilog的安装与使用</a><time datetime="2022-10-31T14:14:11.000Z" title="Created 2022-10-31 22:14:11">2022-10-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/31/%E5%9F%BA%E4%BA%8EPCA%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" title="基于PCA的人脸识别"><img src="/img/PCA_Face_Recognize/top_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于PCA的人脸识别"/></a><div class="content"><a class="title" href="/2022/10/31/%E5%9F%BA%E4%BA%8EPCA%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" title="基于PCA的人脸识别">基于PCA的人脸识别</a><time datetime="2022-10-31T14:07:22.000Z" title="Created 2022-10-31 22:07:22">2022-10-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/31/%E5%9F%BA%E4%BA%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/" title="基于全连接神经网络的MNIST手写数字识别"><img src="/img/MNIST/top_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于全连接神经网络的MNIST手写数字识别"/></a><div class="content"><a class="title" href="/2022/10/31/%E5%9F%BA%E4%BA%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/" title="基于全连接神经网络的MNIST手写数字识别">基于全连接神经网络的MNIST手写数字识别</a><time datetime="2022-10-31T14:00:51.000Z" title="Created 2022-10-31 22:00:51">2022-10-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/31/Apriori/" title="Apriori算法"><img src="/img/Apriori/top_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Apriori算法"/></a><div class="content"><a class="title" href="/2022/10/31/Apriori/" title="Apriori算法">Apriori算法</a><time datetime="2022-10-31T13:48:51.000Z" title="Created 2022-10-31 21:48:51">2022-10-31</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Yuddi</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>